{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.986605,
     "end_time": "2020-05-23T00:16:33.493830",
     "exception": false,
     "start_time": "2020-05-23T00:16:32.507225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append(_dh[0].split(\"knowknow\")[0])\n",
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Counting coocurrences\n",
       "\n",
       "Cultural phenomena are rich in meaning and context. Moreover, the meaning and context are what we care about, so stripping that would be a disservice. \"Consider Geertz:\"\n",
       "> Not only is the semantic structure of the figure a good deal more complex than it appears on the surface, but an analysis of that structure forces one into tracing a multiplicity of referential connections between it and social reality, so that the final picture is one of a configuration of dissimilar meanings out of whose interworking both the expressive power and the rhetorical force of the final symbol derive. (Geertz [1955] 1973, Chapter 8 Ideology as a Cultural System, p. 213)\n",
       "\n",
       "The way people understanding their world shape their action, and understandings are heterogeneous in any community, woven into a complex web of interacting pieces and parts. Understandings are constantly evolving, shifting with every conversation or Breaking News. Any quantitative technique for studying meaning must be able to capture the relational structure of cultural objects, their temporal dynamics, or it cannot be meaning.\n",
       "\n",
       "These considerations motivate how I have designed the data structure and code for this project. My attention to \"cooccurrences\" in what follows is an application of Levi Martin and Lee's (2018) formal approach to meaning. They develop the symbolic formalism I use below, as well as showing several general analytic strategies for inductive, ground-up meaning-making from count data. This approach is quite general, useful for many applications.\n",
       "\n",
       "The process is rather simple, I count cooccurrences between various attributes. For each document, for each citation in that document, I increment a dozen counters, depending on attributes of the citation, paper, journal, or author. This counting process is done once, and can be used as a compressed form of the dataset for all further analyses. In the terminology of Levi Martin and Lee, I am constructing \"hypergraphs\", and I will use their notation in what follows. For example $[c*fy]$ indicates the dataset which maps from $(c, fy) \\to count$.\n",
       "$c$ is the name of the cited work. $fy$ is the publication year of the article which made the citation. $count$ is the number of citations which are at the intersection of these properties.\n",
       "\n",
       "+ $[c]$ the number of citations each document receives\n",
       "+ $[c*fj]$ the number of citations each document receives from each journal's articles\n",
       "+ $[c*fy]$ the number of citations each document receives from each year's articles\n",
       "+ $[fj]$ the number of citations from each journal\n",
       "+ $[fj*fy]$ the number of citations in each journal in each year\n",
       "+ $[t]$ cited term total counts\n",
       "+ $[fy*t]$ cited term time series\n",
       "+ term cooccurrence with citation and journal ($[c*t]$ and [fj*t]$)\n",
       "+ \"author\" counts, the number of citations by each author ($[a]$ $[a*c]$ $[a*j*y]$)\n",
       "+ [c*c]$, the cooccurrence network between citations\n",
       "+ the death of citations can be studied using the $[c*fy]$ hypergraph\n",
       "+ $[c*fj*t]$ could be used for analyzing differential associations of $c$ to $t$ across publication venues\n",
       "+ $[ta*ta]$, $[fa*fa]$, $[t*t]$ and $[c*c]$ open the door to network-scientific methods\n",
       "\n",
       "\n",
       "\n",
       "# References\n",
       "\n",
       "\n",
       "\n",
       "+ Martin, John Levi, and Monica Lee. 2018. “A Formal Approach to Meaning.” Poetics 68(February):10–17.\n",
       "+ Geertz, Clifford. 1973. The Interpretation of Cultures. New York: Basic Books, Inc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showdocs(\"counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.530698",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.512746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# README\n",
    "\n",
    "First, you need to get some data. In accordance with JSTOR's usage policies, I **do not provide any full-text data**. And that's the data you need to use this notebook.\n",
    "You can obtain your own data by requesting full OCR data packages through JSTOR's [Data for Research](https://www.jstor.org/dfr/) initiative. \n",
    "\n",
    "Make sure to read carefully through \"User Settings.\" Set the appropriate settings, and run the entire notebook.\n",
    "\n",
    "This will create a new \"database\" of counts, which can be recalled by running `my_counts = get_cnt( '<DB_NAME_HERE>' )`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015957,
     "end_time": "2020-05-23T00:16:33.563610",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.547653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# User Settings\n",
    "\n",
    "`database_name` is the name you choose for the final dataset of counts\n",
    "\n",
    "`zipdir` is the directory which contains the `.zip` files JSTOR provides to you (not included)\n",
    "\n",
    "`mode` choose between \"basic\" and \"all\" mode\n",
    "\n",
    "1. \"basic\" mode\n",
    "    + this mode is not typically faster than `everything`, but it does reduce RAM overhead\n",
    "        + on ~200k articles the running counters take up more than 16GB RAM\n",
    "        + to counter this, I first run simple statistics, then rerun this notebook again, filtering based on the descriptive statistics\n",
    "    + includes `c` counts, the number of citations each document receives\n",
    "    + includes `c.fj` counts, the number of citations each document receives from each journal's articles\n",
    "    + includes `c.fy` counts, the number of citations each document receives from each year's articles\n",
    "    + includes `fj` counts, the number of citations from each journal\n",
    "    + includes `fj.fy` counts, the number of citations in each journal in each year\n",
    "    + includes `t` `fy.t` counts, for term time series and filtering\n",
    "\n",
    "2. \"all\" mode\n",
    "    + you must run this if you want to run all analyses included in this project\n",
    "    + includes all counts from `basic` mode\n",
    "    + includes term cooccurrence with citation and journal (`c.t` `fj.t`)\n",
    "    + includes \"author\" counts, the number of citations by each author (`a` `a.c` `a.j.y`)\n",
    "    + includes `c.c`, the cooccurrence network between citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.603504",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.581562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "database_name = 'sociology-jstor-basicall'\n",
    "zipdir = 'G:/My Drive/projects/qualitative analysis of literature/pre 5-12-2020/003 process JSTOR output/RaW dAtA/'\n",
    "mode = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016955,
     "end_time": "2020-05-23T00:16:33.638410",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.621455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I use citation and journal filters while counting. \n",
    "This filtering is important when working with large datasets. You can run the \"trend summaries/cysum\" on a `basic` database, and use the variable it automatically generates, `\"<DBNAME>.included_citations\"` to modify which citations to use when computing the `all` database.\n",
    "\n",
    "In most cases, it's best to set `use_included_citations_filter` and `use_included_journals_filter` both to `False` the first time you run this notebook on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.051889,
     "end_time": "2020-05-23T00:16:33.707253",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.655364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_included_citations_filter = True\n",
    "use_included_journals_filter = True\n",
    "\n",
    "# not necessary if you're not filtering based on citations and journals pre-count\n",
    "included_citations = load_variable(\"sociology-jstor.included_citations\")\n",
    "included_journals = ['Acta Sociologica', 'Administrative Science Quarterly', 'American Journal of Political Science', 'American Journal of Sociology', 'American Sociological Review', 'Annual Review of Sociology', 'BMS: Bulletin of Sociological Methodology / Bulletin de Méthodologie Sociologique', 'Berkeley Journal of Sociology', 'Contemporary Sociology', 'European Sociological Review', 'Hitotsubashi Journal of Social Studies', 'Humboldt Journal of Social Relations', 'International Journal of Sociology', 'International Journal of Sociology of the Family', 'International Review of Modern Sociology', 'Journal for the Scientific Study of Religion', 'Journal of Health and Social Behavior', 'Journal of Marriage and Family', 'Language in Society', 'Michigan Sociological Review', 'Polish Sociological Review', 'Review of Religious Research', 'Social Forces', 'Social Indicators Research', 'Social Problems', 'Social Psychology Quarterly', 'Sociological Bulletin', 'Sociological Focus', 'Sociological Forum', 'Sociological Methodology', 'Sociological Perspectives', 'Sociological Theory', 'Sociology', 'Sociology of Education', 'Sociology of Religion', 'Symbolic Interaction', 'The American Sociologist', 'The British Journal of Sociology', 'The Canadian Journal of Sociology', 'The Sociological Quarterly', 'Theory and Society']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043911,
     "end_time": "2020-05-23T00:16:33.768096",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.724185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Terms are iteratively pruned. After `CONSOLIDATE_EVERY_N_CITS` citations are counted, the algorithm will keep only the top `NUM_TERMS_TO_KEEP` terms, blacklisting the rest and not counting them anymore. This doesn't hurt the dataset, but dramatically reduces the RAM overhead and the size of the final dataset on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.019947,
     "end_time": "2020-05-23T00:16:33.804998",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.785051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONSOLIDATE_TERMS = True\n",
    "\n",
    "NUM_TERMS_TO_KEEP = 5000\n",
    "\n",
    "CONSOLIDATE_EVERY_N_CITS = NUM_TERMS_TO_KEEP*3\n",
    "#CONSOLIDATE_EVERY_N_CITS = 1000\n",
    "\n",
    "NPERYEAR = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022938,
     "end_time": "2020-05-23T00:16:33.844891",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.821953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's also convenient to be able to rename various entities. There were a few different names for the Canadian Journal of Sociology. If you want to filter on something other than journals, you'll have to modify the code and add this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.884785",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.862843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "journal_map = {} # default\n",
    "journal_map = {\n",
    "    \"Canadian Journal of Sociology / Cahiers canadiens de sociologie\": 'The Canadian Journal of Sociology',\n",
    "    \"The Canadian Journal of Sociology / Cahiers canadiens de\\n                sociologie\": 'The Canadian Journal of Sociology',\n",
    "    'The Canadian Journal of Sociology / Cahiers canadiens de sociologie': 'The Canadian Journal of Sociology'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.918693",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.900741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.323136,
     "end_time": "2020-05-23T00:16:34.258784",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.935648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "from nltk import sent_tokenize\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./creating variables/'))\n",
    "\n",
    "# library functions for cleaning and extracting in-text citations from OCR\n",
    "from cnt_cooc_jstor_lib import (\n",
    "    citation_iterator, getOuterParens, \n",
    "    Document, ParseError, \n",
    "    clean_metadata\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.301669",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.278730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting ready for term counting\n",
    "from nltk.corpus import stopwords as sw\n",
    "stopwords = set(sw.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.361509",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.338570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zipfiles = list(Path(zipdir).glob(\"*.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018938,
     "end_time": "2020-05-23T00:16:34.398410",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.379472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01697,
     "end_time": "2020-05-23T00:16:34.433332",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.416362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following helper function `file_iterator` iterates through all documents inside a list of zipfiles\n",
    "\n",
    "Each iteration returns:\n",
    "1. the document DOI\n",
    "2. the metadata file contents\n",
    "3. the ocr file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.023937,
     "end_time": "2020-05-23T00:16:34.475220",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.451283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017951,
     "end_time": "2020-05-23T00:16:34.511128",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.493177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`get_page_strings` takes the string contents of an XML file produced by JSTOR. The XML file in question represents the text of a given article. This function cleans the text for OCR peculiarities, and splits the document into pages for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.024942,
     "end_time": "2020-05-23T00:16:34.553025",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.528083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.240891,
     "end_time": "2020-05-23T00:16:34.810862",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.569971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`consolidate terms` was built to eliminate all terms which are not in the top `NUM_TERMS_TO_KEEP`.\n",
    "This is done by sorting `fromyear-term`, or `fy.t` counts in descending order. The top entry here is the term-year pair which accumulated the most appearances in citation contexts. I take the top 1000 `t`'s in this sorted list and preserve them, and blacklist the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.02992,
     "end_time": "2020-05-23T00:16:34.859731",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.829811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "term_whitelist = set()\n",
    "\n",
    "def consolidate_terms():\n",
    "    global term_whitelist, CONSOLIDATION_CUTOFF\n",
    "    \n",
    "\n",
    "    have_now = set(cnt_doc['t'])\n",
    "    # this is where the filtering occurs\n",
    "    \n",
    "    to_keep = set()\n",
    "    if True:\n",
    "        \n",
    "        # takes terms based on the maximum number I can take...\n",
    "        terms = list(cnt_doc['t'].keys())\n",
    "        counts = np.array([cnt_doc['t'][k] for k in terms])\n",
    "        argst = list(reversed(np.argsort(counts)))\n",
    "        \n",
    "        to_keep = [terms[i] for i in argst if '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 2-tuples\n",
    "        to_keep += [terms[i] for i in argst if not '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 1-tuples\n",
    "        \n",
    "        to_remove = have_now.difference(to_keep)\n",
    "        to_remove = set(\"-\".join(x) for x in to_remove)\n",
    "            \n",
    "    \n",
    "    if False:\n",
    "        # takes the top 5000 terms in terms of yearly count\n",
    "        sort_them = sorted(cnt_doc['fy.t'], key=lambda x: -cnt_doc['fy.t'][x])\n",
    "        to_keep = defaultdict(set)\n",
    "        \n",
    "        i = 0\n",
    "        while not len(to_keep) or (\n",
    "            min(len(x) for x in to_keep.values()) < NPERYEAR and \n",
    "            i < len(sort_them)\n",
    "        ):\n",
    "            # adds the term to the year set, if it's not already \"full\"\n",
    "            me = sort_them[i]\n",
    "            me_fy, me_t = me\n",
    "            \n",
    "            # eventually, we don't count it :P\n",
    "            if cnt_doc['t'][me_t] < CONSOLIDATION_CUTOFF:\n",
    "                break\n",
    "            \n",
    "            if len(to_keep[me_fy]) < NPERYEAR:\n",
    "                to_keep[me_fy].add(me_t) \n",
    "            i += 1\n",
    "            \n",
    "        if False: # useful for debugging\n",
    "            print({\n",
    "                k: len(v)\n",
    "                for k,v in to_keep.items()\n",
    "            })\n",
    "            \n",
    "        to_keep = set(chain.from_iterable(x for x in to_keep.values()))\n",
    "        to_remove = have_now.difference(to_keep)\n",
    "    \n",
    "    \n",
    "    # so that we never log counts for these again:\n",
    "    term_whitelist.update([x[0] for x in to_keep])\n",
    "\n",
    "    # the rest of the code is pruning all other term counts for this term in memory\n",
    "    print(\"consolidating... removing\", len(to_remove), 'e.g.', sample(to_remove,5))\n",
    "    \n",
    "    to_prune = ['t','fy.t','fj.t','c.t']\n",
    "    for tp in to_prune:\n",
    "        \n",
    "        whichT = tp.split(\".\").index('t') # this checks where 't' is in the name of the variable (first or second?)\n",
    "\n",
    "        print(\"pruning '%s'...\" % tp)\n",
    "\n",
    "        tydels = [x for x in cnt_doc[tp] if x[ whichT ] in to_remove]\n",
    "            \n",
    "        print(\"old size:\", len(cnt_doc[tp]))\n",
    "        for tr in tydels:\n",
    "            del cnt_doc[tp][tr]\n",
    "            del cnt_ind[tp][tr]\n",
    "        print(\"new size:\", len(cnt_doc[tp]))\n",
    "        \n",
    "    \n",
    "    print(\"final terms: \", \", \".join( sample(list(\"-\".join(list(x)) for x in cnt_doc['t']), 200) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:34.894637",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.877683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Counting algorithm\n",
    "\n",
    "The following cells contain the counting function, which accounts for a document in various ways.\n",
    "This function should be relatively simple to extend, if you want to count other combinations, or different attributes altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.021974,
     "end_time": "2020-05-23T00:16:34.933640",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.911666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt_ind = defaultdict(lambda:defaultdict(int))\n",
    "track_doc = defaultdict(lambda:defaultdict(set))\n",
    "cnt_doc = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "def cnt(term, space, doc):\n",
    "    # it's a set, yo\n",
    "    track_doc[space][term].add(doc)\n",
    "    # update cnt_doc\n",
    "    cnt_doc[space][term] = len(track_doc[space][term])\n",
    "    # update ind count\n",
    "    cnt_ind[space][term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.032995,
     "end_time": "2020-05-23T00:16:34.984587",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.951592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cits = 0\n",
    "last_print = 0\n",
    "citations_skipped = 0\n",
    "\n",
    "def account_for(doc):\n",
    "    global cits, last_print, mode, citations_skipped\n",
    "    \n",
    "    # consolidating \"terms\" counter as I go, to limit RAM overhead\n",
    "    # I'm only interested in the most common 1000\n",
    "    if CONSOLIDATE_TERMS and \\\n",
    "            not len(term_whitelist) and \\\n",
    "            cits - last_print > CONSOLIDATE_EVERY_N_CITS:\n",
    "        print(\"Citation %s\" % cits)\n",
    "        print(\"Term %s\" % len(cnt_doc['t']))\n",
    "        #print(sample(list(cnt_doc['t']), 10))\n",
    "        last_print = cits\n",
    "        consolidate_terms()\n",
    "\n",
    "\n",
    "    if 'citations' not in doc or not len(doc['citations']):\n",
    "        #print(\"No citations\", doc['doi'])\n",
    "        return\n",
    "\n",
    "    for c in doc['citations']:\n",
    "        if 'contextPure' not in c:\n",
    "            raise Exception(\"no contextPure...\")\n",
    "\n",
    "\n",
    "\n",
    "        for cited in c['citations']:\n",
    "            \n",
    "            if use_included_citations_filter and (cited not in included_citations):\n",
    "                citations_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            cits += 1\n",
    "            cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "            # citation\n",
    "            cnt(cited, 'c', doc['doi'])\n",
    "\n",
    "            # journal\n",
    "            cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "            # journal year\n",
    "            cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "            # citation journal\n",
    "            cnt((cited, doc['journal']), 'c.fj', doc['doi'])\n",
    "\n",
    "            # citation year\n",
    "            cnt((cited, doc['year']), 'c.fy', doc['doi'])\n",
    "\n",
    "            \n",
    "        # constructing the tuples set :)\n",
    "        sp = c['contextPure'].lower()\n",
    "        sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp) # removing extraneous characters\n",
    "        sp = re.sub(\"\\s+\", \" \", sp) # removing extra characters\n",
    "        sp = sp.strip()\n",
    "        sp = sp.split() # splitting into words\n",
    "        \n",
    "        sp = [x for x in sp if x not in stopwords] # strip stopwords\n",
    "        \n",
    "        if False:\n",
    "            tups = set(zip(sp[:-1], sp[1:])) # two-word tuples\n",
    "        elif False:\n",
    "            tups = set( (t1,t2) for t1 in sp for t2 in sp if t1!=t2 )# every two-word pair :)\n",
    "        else:\n",
    "            \n",
    "            tups = set( \"-\".join(sorted(x)) for x in set(zip(sp[:-1], sp[1:]))) # two-word tuples\n",
    "            tups.update( sp ) # one-word tuples\n",
    "            \n",
    "        #print(len(tups),c['contextPure'], \"---\", tups)\n",
    "        \n",
    "        if len(term_whitelist):\n",
    "            tups = [x for x in tups if x in term_whitelist]\n",
    "\n",
    "        # just term count, in case we are using the `basic` mode\n",
    "        for t1 in tups:\n",
    "            # term\n",
    "            cnt((t1,), 't', doc['doi'])\n",
    "\n",
    "            # term year\n",
    "            cnt((doc['year'], t1), 'fy.t', doc['doi'])\n",
    "            \n",
    "        \n",
    "        if mode == 'all':\n",
    "\n",
    "\n",
    "            for cited in c['citations']:\n",
    "                \n",
    "                if use_included_citations_filter and (cited not in included_citations):\n",
    "                    continue\n",
    "                    \n",
    "                # term features\n",
    "                for t1 in tups:\n",
    "                    \n",
    "                    # cited work, tuple\n",
    "                    cnt((cited, t1), 'c.t', doc['doi'])\n",
    "\n",
    "                    # term journal\n",
    "                    cnt((doc['journal'], t1), 'fj.t', doc['doi'])\n",
    "\n",
    "                    if False: # eliminating data I'm not using\n",
    "\n",
    "                        # author loop\n",
    "                        for a in doc['authors']:\n",
    "                            # term author\n",
    "                            cnt((a, t1), 'fa.t', doc['doi'])\n",
    "                            \n",
    "                    if len(term_whitelist): # really don't want to do this too early. wait until it's narrowed down to the 5k\n",
    "                        # term term...\n",
    "                        for t2 in tups:\n",
    "                            # if they intersect each other, continue...\n",
    "                            if len(set(t1).intersection(set(t2))) >= min(len(t1),len(t2)):\n",
    "                                continue\n",
    "\n",
    "                            # term term\n",
    "                            cnt((t1,t2), 't.t', doc['doi'])\n",
    "\n",
    "                # author loop\n",
    "                for a in doc['authors']:\n",
    "                    # citation author\n",
    "                    cnt((cited,a), 'c.fa', doc['doi'])\n",
    "\n",
    "                    # year author journal\n",
    "                    cnt((a, doc['journal'], doc['year']), 'fa.fj.fy', doc['doi'])\n",
    "\n",
    "                    # author\n",
    "                    cnt((a,), 'fa', doc['doi'])\n",
    "\n",
    "                # add to counters for citation-citation counts\n",
    "                for cited1 in c['citations']:\n",
    "                    for cited2 in c['citations']:\n",
    "                        if cited1 >= cited2:\n",
    "                            continue\n",
    "\n",
    "                        cnt(( cited1, cited2 ), 'c.c', doc['doi'])\n",
    "                        cnt(( cited1, cited2, doc['year'] ), 'c.c.fy', doc['doi'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:35.019410",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.002456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Master counting cell\n",
    "\n",
    "This cell is **long-running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getname(x):\n",
    "    x = x.split(\"/\")[-1]\n",
    "    x = re.sub(r'(\\.xml|\\.txt)','',x)\n",
    "    return x\n",
    "\n",
    "def jstor_file_iterator_1(zipfiles):\n",
    "    from random import shuffle\n",
    "    \n",
    "    all_files = []\n",
    "    for zf in zipfiles:\n",
    "        archive = ZipFile(zf, 'r')\n",
    "        files = archive.namelist()\n",
    "        names = list(set(getname(x) for x in files))\n",
    "        \n",
    "        all_files += [(archive,name) for name in names]\n",
    "        \n",
    "    shuffle(all_files)\n",
    "        \n",
    "    for archive, name in all_files:\n",
    "        try:\n",
    "            yield(\n",
    "                name.split(\"-\")[-1].replace(\"_\", \"/\"),\n",
    "                archive.read(\"metadata/%s.xml\" % name),\n",
    "                archive.read(\"ocr/%s.txt\" % name).decode('utf8')\n",
    "            )\n",
    "        except KeyError: # some very few articles don't have both\n",
    "            continue\n",
    "            \n",
    "def jstor_file_iterator(zipfiles):\n",
    "    for i, (doi, metadata_str, ocr_str) in enumerate(jstor_file_iterator_1(zipfiles)):\n",
    "        try:\n",
    "            drep = clean_metadata( doi, metadata_str )\n",
    "\n",
    "\n",
    "            # only include journals in the list \"included_journals\"\n",
    "            if use_included_journals_filter and (drep['journal'] not in included_journals):\n",
    "                continue\n",
    "\n",
    "            if debug: print(\"got meta\")\n",
    "\n",
    "            if drep['type'] != 'research-article':\n",
    "                continue\n",
    "\n",
    "            # some types of titles should be immediately ignored\n",
    "            def title_looks_researchy(lt):\n",
    "                lt = lt.lower()\n",
    "                lt = lt.strip()\n",
    "\n",
    "                for x in [\"book review\", 'review essay', 'back matter', 'front matter', 'notes for contributors', 'publication received', 'errata:', 'erratum:']:\n",
    "                    if x in lt:\n",
    "                        return False\n",
    "\n",
    "                for x in [\"commentary and debate\", 'erratum', '']:\n",
    "                    if x == lt:\n",
    "                        return False\n",
    "\n",
    "                return True\n",
    "\n",
    "            lt = drep['title'].lower()\n",
    "            if not title_looks_researchy(lt):\n",
    "                continue\n",
    "\n",
    "            # Don't process the document if there are no authors\n",
    "            if not len(drep['authors']):\n",
    "                continue\n",
    "\n",
    "            drep['content'] = get_content_string(ocr_str)\n",
    "\n",
    "            drep['citations'] = []\n",
    "\n",
    "            # loop through the matching parentheses in the document\n",
    "            for index, (parenStart, parenContents) in enumerate(getOuterParens(drep['content'])):\n",
    "\n",
    "                citations = list(citation_iterator(parenContents))\n",
    "                if not len(citations):\n",
    "                    continue\n",
    "\n",
    "\n",
    "                citation = {\n",
    "                    \"citations\": citations,\n",
    "                    \"contextLeft\": drep['content'][parenStart-400+1:parenStart+1],\n",
    "                    \"contextRight\": drep['content'][parenStart + len(parenContents) + 1:parenStart + len(parenContents) + 1 + 100],\n",
    "                    \"where\": parenStart\n",
    "                }\n",
    "\n",
    "\n",
    "                # cut off any stuff before the first space\n",
    "                first_break_left = re.search(r\"[\\s\\.!\\?]+\", citation['contextLeft'])\n",
    "                if first_break_left is not None:\n",
    "                    clean_start_left = citation['contextLeft'][first_break_left.end():]\n",
    "                else:\n",
    "                    clean_start_left = citation['contextLeft']\n",
    "\n",
    "                # cut off any stuff after the last space\n",
    "                last_break_right = list(re.finditer(r\"[\\s\\.!\\?]+\", citation['contextRight']))\n",
    "                if len(last_break_right):\n",
    "                    clean_end_right = citation['contextRight'][:last_break_right[-1].start()]\n",
    "                else:\n",
    "                    clean_end_right = citation['contextRight']\n",
    "\n",
    "                # we don't want anything more than a sentence\n",
    "\n",
    "                sentence_left = sent_tokenize(clean_start_left)\n",
    "                if len(sentence_left):\n",
    "                    sentence_left = sentence_left[-1]\n",
    "                else:\n",
    "                    sentence_left = \"\"\n",
    "\n",
    "                sentence_right = sent_tokenize(clean_end_right)[0]\n",
    "                if len(sentence_right):\n",
    "                    sentence_right = sentence_right[0]\n",
    "                else:\n",
    "                    sentence_right = \"\"\n",
    "\n",
    "                # finally, strip the parentheses from the string\n",
    "                sentence_left = sentence_left[:-1]\n",
    "                sentence_right = sentence_right[1:]\n",
    "\n",
    "                # add the thing in context\n",
    "                full = sentence_left + \"<CITATION>\" + sentence_right\n",
    "\n",
    "                citation['contextPure'] = sentence_left\n",
    "                #print(full)\n",
    "\n",
    "                drep['citations'].append(citation)\n",
    "            \n",
    "            yield doi, drep\n",
    "            \n",
    "        except ParseError as e:\n",
    "            print(\"parse error...\", e.args, doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 620.295613,
     "end_time": "2020-05-23T00:26:55.331978",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.036365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 ... 0 journals... 0 cited works... 0 authors... 0 terms used... 0 skipped citations... 0 'social' terms\n",
      "Document 1000 ... 37 journals... 4005 cited works... 383 authors... 64272 terms used... 2088 skipped citations... 132 'social' terms\n",
      "Document 2000 ... 40 journals... 8208 cited works... 754 authors... 127737 terms used... 4635 skipped citations... 274 'social' terms\n",
      "Citation 15075\n",
      "Term 138929\n",
      "consolidating... removing 133929 e.g. ['benefit-value', 'conditions-members', 'linked-violence', 'elaborate-independent', 'decoupled']\n",
      "pruning 't'...\n",
      "old size: 138929\n",
      "new size: 5000\n",
      "pruning 'fy.t'...\n",
      "old size: 210650\n",
      "new size: 56089\n",
      "pruning 'fj.t'...\n",
      "old size: 159555\n",
      "new size: 39169\n",
      "pruning 'c.t'...\n",
      "old size: 371000\n",
      "new size: 157187\n",
      "final terms:  courts, measures-two, normal, however, number-total, intergenerational-mobility, perspectives-sociological, acceptable, minimum, conclude, actually, corporate, cases-many, data-present, time-work, political-religious, phenomenon, unequal, simply, require, research-scientific, analysis-comprehensive, logistic-regression, made-study, giving, associated-positively, worker, accordingly, actor, bureaucratic, attitudes, conducted-research, also-suggests, family-may, focuses-research, research-supported, heterogeneous, distribution-unequal, economic-sociology, family-values, cognitive-development, informal, account-fact, development-economic, differential-treatment, american, committee, emphasized-importance, theory, female, foreign, attributed, facts, incidence, interaction, degree, general-health, controversial, democracy, differences-racial, constraints, administration-reagan, independent-variables, dominant-two, conducted, also-scholars, determinants, rest, attendance-religious, sample-women, arises, position, large-number, extent, recommended, institutions-social, suggest, tend-women, children-less, centers, marijuana-use, desirability-effects, must, distance-social, belief-system, shaping, journal, women-working, understanding, central-one, educational-stratification, score, drugs, divorce-found, associated-significantly, based-studies, field, average, analysis-based, agents, historical-particular, case-may, federal-government, participation-rates, know-people, cultural-resources, inner, middle, framework-theoretical, chronic, war, due-women, devoted, importance-increase, initial, instance, play, circumstances, improve, study-used, historical-periods, differences-significant, showed, explicitly, high-levels, psychology-quarterly, intrinsic, distinctions-within, integration, description, position-privileged, black-men, analysis-class, black-communities, citizens, families-poor, american-families, studies-used, levels-social, communities-ethnic, ajs-volume, connected, found, structures, measure-used, men-often, mixed, income-increases, enforcement, assume-likely, met, housing, needs, analyses-sociological, initiatives-policy, strong, percent-year, class-upper, life-social, continued, aspect-one, school, social-support, remained, international-journal, family-income, typically-women, sentiment, helping, still-women, along-lines, contextual, task, whose, recent-study, different-types, likely-men, one-way, experimental-studies, know, positive, reducing, comes, data-sets, eg, article-present, commonly-used, across-vary, economic-growth, resource-theory, fashion, theoretically, differences-substantial, relative, homogeneity, adults-among, measure-scale, different-social, contributes, national-survey\n",
      "Document 3000 ... 40 journals... 11991 cited works... 1151 authors... 5000 terms used... 7259 skipped citations... 442 'social' terms\n",
      "Document 4000 ... 40 journals... 15778 cited works... 1537 authors... 5000 terms used... 9700 skipped citations... 600 'social' terms\n",
      "Document 5000 ... 41 journals... 19684 cited works... 1919 authors... 5000 terms used... 12576 skipped citations... 779 'social' terms\n",
      "Document 6000 ... 41 journals... 22992 cited works... 2298 authors... 5000 terms used... 15524 skipped citations... 937 'social' terms\n",
      "Document 7000 ... 41 journals... 25927 cited works... 2655 authors... 5000 terms used... 18045 skipped citations... 1093 'social' terms\n",
      "Document 8000 ... 41 journals... 28604 cited works... 2979 authors... 5000 terms used... 20425 skipped citations... 1227 'social' terms\n",
      "Document 9000 ... 41 journals... 31243 cited works... 3319 authors... 5000 terms used... 23114 skipped citations... 1374 'social' terms\n",
      "Document 10000 ... 41 journals... 33736 cited works... 3627 authors... 5000 terms used... 25640 skipped citations... 1516 'social' terms\n",
      "Document 11000 ... 41 journals... 36382 cited works... 3986 authors... 5000 terms used... 28119 skipped citations... 1672 'social' terms\n",
      "Document 12000 ... 41 journals... 38859 cited works... 4345 authors... 5000 terms used... 30865 skipped citations... 1822 'social' terms\n",
      "Document 13000 ... 41 journals... 41130 cited works... 4651 authors... 5000 terms used... 34004 skipped citations... 1984 'social' terms\n",
      "Document 14000 ... 41 journals... 43336 cited works... 4961 authors... 5000 terms used... 36566 skipped citations... 2143 'social' terms\n",
      "Document 15000 ... 41 journals... 45372 cited works... 5255 authors... 5000 terms used... 38991 skipped citations... 2288 'social' terms\n",
      "Document 16000 ... 41 journals... 47351 cited works... 5561 authors... 5000 terms used... 41301 skipped citations... 2438 'social' terms\n",
      "Document 17000 ... 41 journals... 49427 cited works... 5836 authors... 5000 terms used... 43792 skipped citations... 2585 'social' terms\n",
      "Document 18000 ... 41 journals... 51182 cited works... 6131 authors... 5000 terms used... 46017 skipped citations... 2721 'social' terms\n",
      "Document 19000 ... 41 journals... 52939 cited works... 6429 authors... 5000 terms used... 48286 skipped citations... 2855 'social' terms\n",
      "Document 20000 ... 41 journals... 54599 cited works... 6696 authors... 5000 terms used... 50541 skipped citations... 2995 'social' terms\n",
      "Document 21000 ... 41 journals... 56646 cited works... 7011 authors... 5000 terms used... 53548 skipped citations... 3154 'social' terms\n",
      "Document 22000 ... 41 journals... 58289 cited works... 7266 authors... 5000 terms used... 55630 skipped citations... 3299 'social' terms\n",
      "Document 23000 ... 41 journals... 59973 cited works... 7520 authors... 5000 terms used... 57997 skipped citations... 3448 'social' terms\n",
      "Document 24000 ... 41 journals... 61676 cited works... 7792 authors... 5000 terms used... 60617 skipped citations... 3598 'social' terms\n",
      "Document 25000 ... 41 journals... 63274 cited works... 8033 authors... 5000 terms used... 62852 skipped citations... 3730 'social' terms\n",
      "Document 26000 ... 41 journals... 65019 cited works... 8343 authors... 5000 terms used... 65762 skipped citations... 3890 'social' terms\n",
      "Document 27000 ... 41 journals... 66667 cited works... 8595 authors... 5000 terms used... 68141 skipped citations... 4035 'social' terms\n",
      "Document 28000 ... 41 journals... 68079 cited works... 8828 authors... 5000 terms used... 70554 skipped citations... 4169 'social' terms\n",
      "Document 29000 ... 41 journals... 69512 cited works... 9101 authors... 5000 terms used... 73232 skipped citations... 4306 'social' terms\n",
      "Document 30000 ... 41 journals... 70854 cited works... 9337 authors... 5000 terms used... 75424 skipped citations... 4443 'social' terms\n",
      "Document 31000 ... 41 journals... 72364 cited works... 9619 authors... 5000 terms used... 78213 skipped citations... 4590 'social' terms\n",
      "Document 32000 ... 41 journals... 73742 cited works... 9886 authors... 5000 terms used... 80820 skipped citations... 4736 'social' terms\n",
      "Document 33000 ... 41 journals... 75028 cited works... 10119 authors... 5000 terms used... 83233 skipped citations... 4874 'social' terms\n",
      "Document 34000 ... 41 journals... 76377 cited works... 10398 authors... 5000 terms used... 85754 skipped citations... 5027 'social' terms\n",
      "Document 35000 ... 41 journals... 77529 cited works... 10611 authors... 5000 terms used... 87899 skipped citations... 5145 'social' terms\n",
      "Document 36000 ... 41 journals... 78559 cited works... 10853 authors... 5000 terms used... 89937 skipped citations... 5277 'social' terms\n",
      "Document 37000 ... 41 journals... 79729 cited works... 11088 authors... 5000 terms used... 92671 skipped citations... 5420 'social' terms\n",
      "Document 38000 ... 41 journals... 81025 cited works... 11332 authors... 5000 terms used... 94951 skipped citations... 5555 'social' terms\n",
      "Document 39000 ... 41 journals... 82270 cited works... 11583 authors... 5000 terms used... 97218 skipped citations... 5700 'social' terms\n",
      "Document 40000 ... 41 journals... 83494 cited works... 11859 authors... 5000 terms used... 99765 skipped citations... 5849 'social' terms\n",
      "Document 41000 ... 41 journals... 84881 cited works... 12111 authors... 5000 terms used... 102869 skipped citations... 6006 'social' terms\n",
      "Document 42000 ... 41 journals... 86147 cited works... 12379 authors... 5000 terms used... 106297 skipped citations... 6156 'social' terms\n",
      "Document 43000 ... 41 journals... 87056 cited works... 12564 authors... 5000 terms used... 108547 skipped citations... 6280 'social' terms\n",
      "Document 44000 ... 41 journals... 88190 cited works... 12781 authors... 5000 terms used... 110968 skipped citations... 6424 'social' terms\n",
      "Document 45000 ... 41 journals... 89451 cited works... 13012 authors... 5000 terms used... 114036 skipped citations... 6559 'social' terms\n",
      "Document 46000 ... 41 journals... 90758 cited works... 13280 authors... 5000 terms used... 117033 skipped citations... 6723 'social' terms\n",
      "Document 47000 ... 41 journals... 91876 cited works... 13525 authors... 5000 terms used... 119841 skipped citations... 6876 'social' terms\n",
      "Document 48000 ... 41 journals... 92875 cited works... 13745 authors... 5000 terms used... 122360 skipped citations... 7011 'social' terms\n",
      "Document 49000 ... 41 journals... 93981 cited works... 13972 authors... 5000 terms used... 125203 skipped citations... 7153 'social' terms\n",
      "Document 50000 ... 41 journals... 94810 cited works... 14204 authors... 5000 terms used... 127185 skipped citations... 7277 'social' terms\n",
      "Document 51000 ... 41 journals... 95651 cited works... 14416 authors... 5000 terms used... 129508 skipped citations... 7422 'social' terms\n",
      "Document 52000 ... 41 journals... 96539 cited works... 14646 authors... 5000 terms used... 131721 skipped citations... 7554 'social' terms\n",
      "Document 53000 ... 41 journals... 97560 cited works... 14884 authors... 5000 terms used... 134190 skipped citations... 7717 'social' terms\n",
      "Document 54000 ... 41 journals... 98395 cited works... 15069 authors... 5000 terms used... 136473 skipped citations... 7850 'social' terms\n",
      "Document 55000 ... 41 journals... 99293 cited works... 15294 authors... 5000 terms used... 139052 skipped citations... 7990 'social' terms\n",
      "Document 56000 ... 41 journals... 100179 cited works... 15516 authors... 5000 terms used... 141950 skipped citations... 8136 'social' terms\n",
      "Document 57000 ... 41 journals... 101199 cited works... 15768 authors... 5000 terms used... 144235 skipped citations... 8291 'social' terms\n",
      "Document 58000 ... 41 journals... 102132 cited works... 16002 authors... 5000 terms used... 147013 skipped citations... 8435 'social' terms\n",
      "Document 59000 ... 41 journals... 102984 cited works... 16207 authors... 5000 terms used... 149535 skipped citations... 8573 'social' terms\n",
      "Document 60000 ... 41 journals... 103808 cited works... 16412 authors... 5000 terms used... 152055 skipped citations... 8720 'social' terms\n",
      "Document 61000 ... 41 journals... 104674 cited works... 16608 authors... 5000 terms used... 154791 skipped citations... 8861 'social' terms\n",
      "Document 62000 ... 41 journals... 105515 cited works... 16804 authors... 5000 terms used... 157672 skipped citations... 9018 'social' terms\n",
      "Document 63000 ... 41 journals... 106187 cited works... 17001 authors... 5000 terms used... 159960 skipped citations... 9143 'social' terms\n",
      "Document 64000 ... 41 journals... 106826 cited works... 17180 authors... 5000 terms used... 161776 skipped citations... 9263 'social' terms\n",
      "Document 65000 ... 41 journals... 107523 cited works... 17390 authors... 5000 terms used... 163889 skipped citations... 9406 'social' terms\n",
      "Document 66000 ... 41 journals... 108271 cited works... 17575 authors... 5000 terms used... 166523 skipped citations... 9527 'social' terms\n",
      "Document 67000 ... 41 journals... 109007 cited works... 17788 authors... 5000 terms used... 169249 skipped citations... 9672 'social' terms\n",
      "Document 68000 ... 41 journals... 109690 cited works... 17991 authors... 5000 terms used... 171774 skipped citations... 9820 'social' terms\n",
      "Document 69000 ... 41 journals... 110410 cited works... 18211 authors... 5000 terms used... 173910 skipped citations... 9984 'social' terms\n",
      "Document 70000 ... 41 journals... 111109 cited works... 18409 authors... 5000 terms used... 176795 skipped citations... 10132 'social' terms\n",
      "Document 71000 ... 41 journals... 111722 cited works... 18618 authors... 5000 terms used... 179339 skipped citations... 10274 'social' terms\n",
      "Document 72000 ... 41 journals... 112259 cited works... 18783 authors... 5000 terms used... 181091 skipped citations... 10401 'social' terms\n",
      "Document 73000 ... 41 journals... 112892 cited works... 18975 authors... 5000 terms used... 183587 skipped citations... 10523 'social' terms\n",
      "Document 74000 ... 41 journals... 113614 cited works... 19214 authors... 5000 terms used... 186346 skipped citations... 10666 'social' terms\n",
      "Document 75000 ... 41 journals... 114303 cited works... 19426 authors... 5000 terms used... 188913 skipped citations... 10808 'social' terms\n",
      "Document 76000 ... 41 journals... 114999 cited works... 19626 authors... 5000 terms used... 191607 skipped citations... 10947 'social' terms\n",
      "Document 77000 ... 41 journals... 115597 cited works... 19810 authors... 5000 terms used... 194094 skipped citations... 11097 'social' terms\n",
      "Document 78000 ... 41 journals... 116286 cited works... 20025 authors... 5000 terms used... 197306 skipped citations... 11249 'social' terms\n",
      "Document 79000 ... 41 journals... 116819 cited works... 20193 authors... 5000 terms used... 199704 skipped citations... 11390 'social' terms\n",
      "Document 80000 ... 41 journals... 117288 cited works... 20357 authors... 5000 terms used... 201988 skipped citations... 11517 'social' terms\n",
      "Document 81000 ... 41 journals... 117888 cited works... 20532 authors... 5000 terms used... 205009 skipped citations... 11657 'social' terms\n",
      "Document 82000 ... 41 journals... 118435 cited works... 20702 authors... 5000 terms used... 207538 skipped citations... 11787 'social' terms\n",
      "Document 83000 ... 41 journals... 118932 cited works... 20918 authors... 5000 terms used... 209998 skipped citations... 11926 'social' terms\n",
      "Document 84000 ... 41 journals... 119424 cited works... 21115 authors... 5000 terms used... 212325 skipped citations... 12060 'social' terms\n",
      "Document 85000 ... 41 journals... 120016 cited works... 21325 authors... 5000 terms used... 215005 skipped citations... 12207 'social' terms\n",
      "Document 86000 ... 41 journals... 120550 cited works... 21490 authors... 5000 terms used... 217360 skipped citations... 12340 'social' terms\n",
      "Document 87000 ... 41 journals... 120991 cited works... 21667 authors... 5000 terms used... 219758 skipped citations... 12473 'social' terms\n",
      "Document 88000 ... 41 journals... 121507 cited works... 21880 authors... 5000 terms used... 222288 skipped citations... 12606 'social' terms\n",
      "Document 89000 ... 41 journals... 122055 cited works... 22074 authors... 5000 terms used... 224987 skipped citations... 12755 'social' terms\n",
      "Document 90000 ... 41 journals... 122511 cited works... 22260 authors... 5000 terms used... 227579 skipped citations... 12889 'social' terms\n",
      "Document 91000 ... 41 journals... 123004 cited works... 22481 authors... 5000 terms used... 229932 skipped citations... 13026 'social' terms\n",
      "Document 92000 ... 41 journals... 123362 cited works... 22633 authors... 5000 terms used... 231941 skipped citations... 13152 'social' terms\n",
      "Document 93000 ... 41 journals... 123887 cited works... 22865 authors... 5000 terms used... 234895 skipped citations... 13301 'social' terms\n",
      "parse error... ('No valid year found',) 10.2307/26650770\n",
      "Document 94000 ... 41 journals... 124355 cited works... 23061 authors... 5000 terms used... 237218 skipped citations... 13435 'social' terms\n",
      "Document 95000 ... 41 journals... 124804 cited works... 23232 authors... 5000 terms used... 239781 skipped citations... 13574 'social' terms\n",
      "parse error... ('No valid year found',) 10.2307/26650789\n",
      "Document 96000 ... 41 journals... 125264 cited works... 23424 authors... 5000 terms used... 242351 skipped citations... 13700 'social' terms\n",
      "Document 97000 ... 41 journals... 125706 cited works... 23659 authors... 5000 terms used... 244903 skipped citations... 13841 'social' terms\n",
      "Document 98000 ... 41 journals... 126187 cited works... 23821 authors... 5000 terms used... 247705 skipped citations... 13990 'social' terms\n",
      "Document 99000 ... 41 journals... 126643 cited works... 24036 authors... 5000 terms used... 250261 skipped citations... 14130 'social' terms\n",
      "Document 100000 ... 41 journals... 127069 cited works... 24215 authors... 5000 terms used... 253176 skipped citations... 14267 'social' terms\n",
      "Document 101000 ... 41 journals... 127495 cited works... 24381 authors... 5000 terms used... 255609 skipped citations... 14414 'social' terms\n",
      "Document 102000 ... 41 journals... 127856 cited works... 24538 authors... 5000 terms used... 257941 skipped citations... 14553 'social' terms\n",
      "Document 103000 ... 41 journals... 128198 cited works... 24703 authors... 5000 terms used... 260312 skipped citations... 14689 'social' terms\n",
      "Document 104000 ... 41 journals... 128520 cited works... 24866 authors... 5000 terms used... 262095 skipped citations... 14816 'social' terms\n",
      "Document 105000 ... 41 journals... 128864 cited works... 25047 authors... 5000 terms used... 264760 skipped citations... 14958 'social' terms\n",
      "Document 106000 ... 41 journals... 129233 cited works... 25216 authors... 5000 terms used... 267541 skipped citations... 15079 'social' terms\n",
      "Document 107000 ... 41 journals... 129680 cited works... 25406 authors... 5000 terms used... 270347 skipped citations... 15226 'social' terms\n",
      "Document 108000 ... 41 journals... 130059 cited works... 25582 authors... 5000 terms used... 273150 skipped citations... 15358 'social' terms\n",
      "Document 109000 ... 41 journals... 130347 cited works... 25759 authors... 5000 terms used... 275391 skipped citations... 15493 'social' terms\n",
      "Document 110000 ... 41 journals... 130730 cited works... 25939 authors... 5000 terms used... 278041 skipped citations... 15629 'social' terms\n",
      "Document 111000 ... 41 journals... 131028 cited works... 26115 authors... 5000 terms used... 280534 skipped citations... 15763 'social' terms\n",
      "Document 112000 ... 41 journals... 131311 cited works... 26303 authors... 5000 terms used... 282657 skipped citations... 15900 'social' terms\n",
      "Document 113000 ... 41 journals... 131632 cited works... 26476 authors... 5000 terms used... 284847 skipped citations... 16010 'social' terms\n",
      "Document 114000 ... 41 journals... 131918 cited works... 26654 authors... 5000 terms used... 287296 skipped citations... 16139 'social' terms\n",
      "Document 115000 ... 41 journals... 132270 cited works... 26853 authors... 5000 terms used... 290082 skipped citations... 16293 'social' terms\n",
      "Document 116000 ... 41 journals... 132478 cited works... 27012 authors... 5000 terms used... 291998 skipped citations... 16407 'social' terms\n",
      "Document 117000 ... 41 journals... 132806 cited works... 27163 authors... 5000 terms used... 294556 skipped citations... 16552 'social' terms\n",
      "Document 118000 ... 41 journals... 133123 cited works... 27372 authors... 5000 terms used... 297203 skipped citations... 16691 'social' terms\n",
      "Document 119000 ... 41 journals... 133467 cited works... 27575 authors... 5000 terms used... 300392 skipped citations... 16843 'social' terms\n",
      "Document 120000 ... 41 journals... 133692 cited works... 27732 authors... 5000 terms used... 302385 skipped citations... 16969 'social' terms\n",
      "Document 121000 ... 41 journals... 133927 cited works... 27876 authors... 5000 terms used... 304663 skipped citations... 17095 'social' terms\n",
      "Document 122000 ... 41 journals... 134189 cited works... 28055 authors... 5000 terms used... 306883 skipped citations... 17233 'social' terms\n",
      "Document 123000 ... 41 journals... 134445 cited works... 28212 authors... 5000 terms used... 309358 skipped citations... 17372 'social' terms\n",
      "Document 124000 ... 41 journals... 134677 cited works... 28365 authors... 5000 terms used... 311697 skipped citations... 17488 'social' terms\n",
      "Document 125000 ... 41 journals... 134946 cited works... 28510 authors... 5000 terms used... 314237 skipped citations... 17618 'social' terms\n",
      "Document 126000 ... 41 journals... 135200 cited works... 28685 authors... 5000 terms used... 317594 skipped citations... 17756 'social' terms\n",
      "Document 127000 ... 41 journals... 135423 cited works... 28839 authors... 5000 terms used... 319987 skipped citations... 17890 'social' terms\n",
      "Document 128000 ... 41 journals... 135651 cited works... 28989 authors... 5000 terms used... 322730 skipped citations... 18026 'social' terms\n",
      "Document 129000 ... 41 journals... 135835 cited works... 29118 authors... 5000 terms used... 324492 skipped citations... 18142 'social' terms\n",
      "Document 130000 ... 41 journals... 136077 cited works... 29272 authors... 5000 terms used... 327036 skipped citations... 18286 'social' terms\n",
      "Document 131000 ... 41 journals... 136285 cited works... 29418 authors... 5000 terms used... 329392 skipped citations... 18413 'social' terms\n",
      "Document 132000 ... 41 journals... 136475 cited works... 29569 authors... 5000 terms used... 331660 skipped citations... 18526 'social' terms\n",
      "Document 133000 ... 41 journals... 136694 cited works... 29723 authors... 5000 terms used... 333942 skipped citations... 18672 'social' terms\n",
      "Document 134000 ... 41 journals... 136881 cited works... 29881 authors... 5000 terms used... 336862 skipped citations... 18815 'social' terms\n",
      "Document 135000 ... 41 journals... 137037 cited works... 30024 authors... 5000 terms used... 338877 skipped citations... 18943 'social' terms\n",
      "Document 136000 ... 41 journals... 137229 cited works... 30171 authors... 5000 terms used... 341314 skipped citations... 19075 'social' terms\n",
      "Document 137000 ... 41 journals... 137436 cited works... 30338 authors... 5000 terms used... 344466 skipped citations... 19206 'social' terms\n",
      "Document 138000 ... 41 journals... 137655 cited works... 30505 authors... 5000 terms used... 347232 skipped citations... 19334 'social' terms\n",
      "Document 139000 ... 41 journals... 137864 cited works... 30651 authors... 5000 terms used... 350515 skipped citations... 19465 'social' terms\n",
      "Document 140000 ... 41 journals... 138027 cited works... 30803 authors... 5000 terms used... 352754 skipped citations... 19591 'social' terms\n",
      "Document 141000 ... 41 journals... 138186 cited works... 30951 authors... 5000 terms used... 355264 skipped citations... 19719 'social' terms\n",
      "Document 142000 ... 41 journals... 138370 cited works... 31135 authors... 5000 terms used... 357988 skipped citations... 19851 'social' terms\n",
      "Document 143000 ... 41 journals... 138511 cited works... 31309 authors... 5000 terms used... 360623 skipped citations... 19971 'social' terms\n",
      "Document 144000 ... 41 journals... 138650 cited works... 31465 authors... 5000 terms used... 363604 skipped citations... 20110 'social' terms\n",
      "Document 145000 ... 41 journals... 138810 cited works... 31624 authors... 5000 terms used... 366257 skipped citations... 20243 'social' terms\n",
      "Document 146000 ... 41 journals... 138963 cited works... 31776 authors... 5000 terms used... 368969 skipped citations... 20380 'social' terms\n",
      "Document 147000 ... 41 journals... 139089 cited works... 31899 authors... 5000 terms used... 371263 skipped citations... 20501 'social' terms\n",
      "Document 148000 ... 41 journals... 139221 cited works... 32054 authors... 5000 terms used... 373344 skipped citations... 20619 'social' terms\n",
      "Document 149000 ... 41 journals... 139325 cited works... 32181 authors... 5000 terms used... 375424 skipped citations... 20729 'social' terms\n",
      "Document 150000 ... 41 journals... 139461 cited works... 32345 authors... 5000 terms used... 378195 skipped citations... 20874 'social' terms\n",
      "Document 151000 ... 41 journals... 139580 cited works... 32478 authors... 5000 terms used... 380364 skipped citations... 20991 'social' terms\n",
      "Document 152000 ... 41 journals... 139687 cited works... 32623 authors... 5000 terms used... 383104 skipped citations... 21113 'social' terms\n",
      "Document 153000 ... 41 journals... 139823 cited works... 32766 authors... 5000 terms used... 385502 skipped citations... 21242 'social' terms\n",
      "Document 154000 ... 41 journals... 139928 cited works... 32903 authors... 5000 terms used... 387538 skipped citations... 21360 'social' terms\n",
      "Document 155000 ... 41 journals... 140037 cited works... 33054 authors... 5000 terms used... 390456 skipped citations... 21484 'social' terms\n",
      "Document 156000 ... 41 journals... 140111 cited works... 33181 authors... 5000 terms used... 392655 skipped citations... 21604 'social' terms\n",
      "Document 157000 ... 41 journals... 140206 cited works... 33359 authors... 5000 terms used... 395402 skipped citations... 21765 'social' terms\n",
      "Document 158000 ... 41 journals... 140295 cited works... 33509 authors... 5000 terms used... 398069 skipped citations... 21892 'social' terms\n",
      "Document 159000 ... 41 journals... 140414 cited works... 33686 authors... 5000 terms used... 400623 skipped citations... 22025 'social' terms\n",
      "Document 160000 ... 41 journals... 140497 cited works... 33832 authors... 5000 terms used... 402992 skipped citations... 22164 'social' terms\n",
      "Document 161000 ... 41 journals... 140581 cited works... 33958 authors... 5000 terms used... 405359 skipped citations... 22294 'social' terms\n",
      "Document 162000 ... 41 journals... 140669 cited works... 34092 authors... 5000 terms used... 407669 skipped citations... 22419 'social' terms\n",
      "Document 163000 ... 41 journals... 140740 cited works... 34235 authors... 5000 terms used... 410276 skipped citations... 22535 'social' terms\n",
      "Document 164000 ... 41 journals... 140820 cited works... 34398 authors... 5000 terms used... 412781 skipped citations... 22659 'social' terms\n",
      "Document 165000 ... 41 journals... 140889 cited works... 34551 authors... 5000 terms used... 414935 skipped citations... 22798 'social' terms\n",
      "Document 166000 ... 41 journals... 140973 cited works... 34696 authors... 5000 terms used... 418345 skipped citations... 22938 'social' terms\n",
      "Document 167000 ... 41 journals... 141048 cited works... 34851 authors... 5000 terms used... 421095 skipped citations... 23064 'social' terms\n",
      "Document 168000 ... 41 journals... 141122 cited works... 35002 authors... 5000 terms used... 423559 skipped citations... 23201 'social' terms\n",
      "Document 169000 ... 41 journals... 141184 cited works... 35145 authors... 5000 terms used... 426185 skipped citations... 23333 'social' terms\n",
      "Document 170000 ... 41 journals... 141229 cited works... 35275 authors... 5000 terms used... 428642 skipped citations... 23452 'social' terms\n",
      "Document 171000 ... 41 journals... 141290 cited works... 35417 authors... 5000 terms used... 431166 skipped citations... 23581 'social' terms\n",
      "Document 172000 ... 41 journals... 141329 cited works... 35571 authors... 5000 terms used... 433598 skipped citations... 23697 'social' terms\n",
      "Document 173000 ... 41 journals... 141388 cited works... 35723 authors... 5000 terms used... 436661 skipped citations... 23839 'social' terms\n",
      "Document 174000 ... 41 journals... 141422 cited works... 35868 authors... 5000 terms used... 438694 skipped citations... 23950 'social' terms\n",
      "Document 175000 ... 41 journals... 141449 cited works... 36001 authors... 5000 terms used... 441039 skipped citations... 24087 'social' terms\n",
      "Document 176000 ... 41 journals... 141488 cited works... 36120 authors... 5000 terms used... 443983 skipped citations... 24214 'social' terms\n",
      "Document 177000 ... 41 journals... 141507 cited works... 36289 authors... 5000 terms used... 446523 skipped citations... 24345 'social' terms\n",
      "Document 178000 ... 41 journals... 141528 cited works... 36420 authors... 5000 terms used... 448845 skipped citations... 24470 'social' terms\n",
      "Document 179000 ... 41 journals... 141558 cited works... 36543 authors... 5000 terms used... 451261 skipped citations... 24595 'social' terms\n",
      "Document 180000 ... 41 journals... 141582 cited works... 36691 authors... 5000 terms used... 454158 skipped citations... 24732 'social' terms\n",
      "Document 181000 ... 41 journals... 141589 cited works... 36807 authors... 5000 terms used... 456376 skipped citations... 24833 'social' terms\n",
      "Document 182000 ... 41 journals... 141596 cited works... 36958 authors... 5000 terms used... 459122 skipped citations... 24971 'social' terms\n",
      "Document 183000 ... 41 journals... 141603 cited works... 37091 authors... 5000 terms used... 461318 skipped citations... 25090 'social' terms\n",
      "Document 184000 ... 41 journals... 141607 cited works... 37241 authors... 5000 terms used... 464083 skipped citations... 25236 'social' terms\n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "total_count = Counter()\n",
    "doc_count = Counter()\n",
    "pair_count = Counter()\n",
    "\n",
    "debug = False\n",
    "\n",
    "\n",
    "for i, (doi, drep) in enumerate( jstor_file_iterator(zipfiles) ):\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Document\", i, \"...\", \n",
    "              len(cnt_doc['fj'].keys()), \"journals...\", \n",
    "              len(cnt_doc['c'].keys()), \"cited works...\", \n",
    "              len(cnt_doc['fa'].keys()), \"authors...\",\n",
    "              len(cnt_doc['t'].keys()), \"terms used...\",\n",
    "              citations_skipped, \"skipped citations...\",\n",
    "              cnt_doc['t'][('social',)], \"'social' terms\"\n",
    "             )\n",
    "\n",
    "    # sometimes multiple journal names map onto the same journal, for all intents and purposes\n",
    "    if drep['journal'] in journal_map:\n",
    "        drep['journal'] = journal_map[drep['journal']]  \n",
    "\n",
    "    # only include journals in the list \"included_journals\"\n",
    "    if use_included_journals_filter and (drep['journal'] not in included_journals):\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    # now that we have all the information we need,\n",
    "    # we simply need to \"count\" this document in a few different ways\n",
    "    account_for(drep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('social',), ('played',), ('ever',), ('candidates',), ('money',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cnt_doc['t'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in cnt_doc['t'] if not '-' in x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(cnt_doc['t'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj 41\n",
      "c 141608\n",
      "fa 37329\n",
      "t 5000\n",
      "fy 104\n",
      "fj.fy 1849\n",
      "c.fj 463963\n",
      "c.fy 588668\n",
      "fy.t 238387\n",
      "c.t 9661193\n",
      "fj.t 164358\n",
      "c.fa 1328474\n",
      "fa.fj.fy 68269\n",
      "c.c 1019555\n",
      "c.c.fy 1122173\n",
      "t.t 10174838\n"
     ]
    }
   ],
   "source": [
    "for k,v in cnt_doc.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Save the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sociology-jstor-basicall.doc ___ fj\n",
      "Saving sociology-jstor-basicall.doc ___ c\n",
      "Saving sociology-jstor-basicall.doc ___ fa\n",
      "Saving sociology-jstor-basicall.doc ___ t\n",
      "Saving sociology-jstor-basicall.doc ___ fy\n",
      "Saving sociology-jstor-basicall.doc ___ fj.fy\n",
      "Saving sociology-jstor-basicall.doc ___ c.fj\n",
      "Saving sociology-jstor-basicall.doc ___ c.fy\n",
      "Saving sociology-jstor-basicall.doc ___ fy.t\n",
      "Saving sociology-jstor-basicall.doc ___ c.t\n",
      "Saving sociology-jstor-basicall.doc ___ fj.t\n",
      "Saving sociology-jstor-basicall.doc ___ c.fa\n",
      "Saving sociology-jstor-basicall.doc ___ fa.fj.fy\n",
      "Saving sociology-jstor-basicall.doc ___ c.c\n",
      "Saving sociology-jstor-basicall.doc ___ c.c.fy\n",
      "Saving sociology-jstor-basicall.doc ___ t.t\n"
     ]
    }
   ],
   "source": [
    "save_cnt(\"%s.doc\"%database_name, cnt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sociology-jstor-basicall.ind ___ fy\n",
      "Saving sociology-jstor-basicall.ind ___ c\n",
      "Saving sociology-jstor-basicall.ind ___ fj\n",
      "Saving sociology-jstor-basicall.ind ___ fj.fy\n",
      "Saving sociology-jstor-basicall.ind ___ c.fj\n",
      "Saving sociology-jstor-basicall.ind ___ c.fy\n",
      "Saving sociology-jstor-basicall.ind ___ t\n",
      "Saving sociology-jstor-basicall.ind ___ fy.t\n",
      "Saving sociology-jstor-basicall.ind ___ c.t\n",
      "Saving sociology-jstor-basicall.ind ___ fj.t\n",
      "Saving sociology-jstor-basicall.ind ___ c.fa\n",
      "Saving sociology-jstor-basicall.ind ___ fa.fj.fy\n",
      "Saving sociology-jstor-basicall.ind ___ fa\n",
      "Saving sociology-jstor-basicall.ind ___ c.c\n",
      "Saving sociology-jstor-basicall.ind ___ c.c.fy\n",
      "Saving sociology-jstor-basicall.ind ___ t.t\n"
     ]
    }
   ],
   "source": [
    "save_cnt(\"%s.ind\"%database_name, cnt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"commentbox\"></div><script>\n",
       "    function comment_box_init(){commentBox('5738033810767872-proj');}\n",
       "    </script>\n",
       "    <script onload='comment_box_init()' src=\"https://unpkg.com/commentbox.io/dist/commentBox.min.js\"></script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "output_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "parameters": {},
   "start_time": "2020-05-23T00:16:31.253561",
   "version": "2.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
